{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9417b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import model\n",
    "import verifier\n",
    "import cscUpdater\n",
    "import updater\n",
    "\n",
    "import importlib as imp\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import dill as pickle\n",
    "\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import acsDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cf5dcdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 #train-test split\n",
    "\n",
    "acs_task = 'income' # options: employment, income, public_coverage, mobility, and travel_time.\n",
    "acs_year = 2018 #must be >= 2014. Upper bound unknown.\n",
    "acs_states = ['CA']\n",
    "acs_horizon='1-Year' #1-Year or 5-Year\n",
    "acs_survey='person' #'person' or 'household'\n",
    "\n",
    "# for subsampling rows: can specify first and last of data to be pulled. currently pulling everything.\n",
    "row_start = 0\n",
    "row_end = 100000\n",
    "\n",
    "# for subsampling columns. note: can only subsample consecutive columns with current implementation\n",
    "col_start=0\n",
    "col_end=-1\n",
    "\n",
    "[train_x, train_y, test_x, test_y, demo_group_functions, demo_group_indicators, min_age, mid_age] = acsDataParallel.get_data(test_size, acs_task, acs_year, acs_states,acs_horizon=acs_horizon, acs_survey=acs_survey, row_start = row_start,row_end = row_end, col_start=col_start, col_end=col_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bb5733f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1(X):\n",
    "    return ((X['WKHP'] == 40))\n",
    "\n",
    "truth_series = g1(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf1 = sk.ensemble.RandomForestClassifier(n_estimators=100, max_depth=11)\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1GPU = convert(clf1, 'pytorch')\n",
    "clf1GPU.to('cuda')\n",
    "\n",
    "def h1(x):\n",
    "    return clf1GPU.predict(x)\n",
    "\n",
    "def g2(X):\n",
    "    return ((X['WKHP'] >= 20))\n",
    "\n",
    "truth_series = g2(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf2 = sk.ensemble.RandomForestClassifier(n_estimators=100, max_depth=11)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf2GPU = convert(clf1, 'pytorch')\n",
    "clf2GPU.to('cuda')\n",
    "def h2(x):\n",
    "    return clf2GPU.predict(x)\n",
    "\n",
    "def g3(X):\n",
    "    return ((X['RAC1P'] != 1))\n",
    "\n",
    "truth_series = g3(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf3 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=13)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf3GPU = convert(clf1, 'pytorch')\n",
    "clf3GPU.to('cuda')\n",
    "def h3(x):\n",
    "    return clf3GPU.predict(x)\n",
    "\n",
    "def g4(X):\n",
    "    return ((X['RAC1P'] != 0))\n",
    "\n",
    "truth_series = g4(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf4 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=15)\n",
    "clf4.fit(X_train,y_train)\n",
    "clf4GPU = convert(clf1, 'pytorch')\n",
    "clf4GPU.to('cuda')\n",
    "def h4(x):\n",
    "    return clf4GPU.predict(x)\n",
    "\n",
    "def g5(X):\n",
    "    return (X['AGEP'] >= 70)\n",
    "\n",
    "truth_series = g5(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf5 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "clf5.fit(X_train,y_train)\n",
    "clf5GPU = convert(clf1, 'pytorch')\n",
    "clf5GPU.to('cuda')\n",
    "def h5(x):\n",
    "    return clf5GPU.predict(x)\n",
    "\n",
    "def g6(X):\n",
    "    return (X['SCHL'] >= 16)\n",
    "\n",
    "truth_series = g6(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf6 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=15)\n",
    "clf6.fit(X_train,y_train)\n",
    "clf6GPU = convert(clf1, 'pytorch')\n",
    "clf6GPU.to('cuda')\n",
    "def h6(x):\n",
    "    return clf6GPU.predict(x)\n",
    "\n",
    "def g7(X):\n",
    "    return (X['AGEP'] >= 62)\n",
    "\n",
    "truth_series = g7(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf7 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200,max_depth = 3,random_state=0)\n",
    "clf7.fit(X_train,y_train)\n",
    "clf7GPU = convert(clf1, 'pytorch')\n",
    "clf7GPU.to('cuda')\n",
    "def h7(x):\n",
    "    return clf7GPU.predict(x)\n",
    "\n",
    "def g8(X):\n",
    "    return (X['SCHL'] >= 16)\n",
    "\n",
    "truth_series = g8(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf8 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200,max_depth = 3,random_state=0)\n",
    "clf8.fit(X_train,y_train)\n",
    "clf8GPU = convert(clf1, 'pytorch')\n",
    "clf8GPU.to('cuda')\n",
    "def h8(x):\n",
    "    return clf8GPU.predict(x)\n",
    "\n",
    "def g9(X):\n",
    "    return (X['SCHL'] <= 18)\n",
    "\n",
    "truth_series = g8(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf9 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=300,max_depth = 8,random_state=0)\n",
    "clf9.fit(X_train,y_train)\n",
    "clf9GPU = convert(clf1, 'pytorch')\n",
    "clf9GPU.to('cuda')\n",
    "\n",
    "def h9(x):\n",
    "    return clf9GPU.predict(x)\n",
    "\n",
    "def g10(X):\n",
    "    return (X['SCHL'] >= 1)\n",
    "\n",
    "truth_series = g10(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf10 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=300,max_depth = 8,random_state=0)\n",
    "clf10.fit(X_train,y_train)\n",
    "clf10GPU = convert(clf1, 'pytorch')\n",
    "clf10GPU.to('cuda')\n",
    "def h10(x):\n",
    "    return clf10GPU.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2e6ada22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_size(x, group):\n",
    "# helper function that checks that the discovered group isn't too small to run on\n",
    "    g_indices = group(x) == 1\n",
    "    g_xs = x[g_indices]\n",
    "    if len(g_xs) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "45b843d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = DecisionTreeClassifier(max_depth = 1, random_state=0)\n",
    "initial_model.fit(train_x, train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f4f6cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_without_group(permutation, mod_without_group, predicate_list, group_list, train_x, train_y, test_x, test_y):\n",
    "    for index in permutation:\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(mod_without_group, test_x, test_y, predicate_list[index],group_list[index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(mod_without_group, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "    return mod_without_group.test_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "3a44dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a01f6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_worst_perm(train_x, train_y, test_x, test_y, max_perms = None):\n",
    "    start_time = time.time()\n",
    "    permutations = list(itertools.permutations([1,5,6,9,10]))\n",
    "    best_error = 100\n",
    "    worst_error = 0\n",
    "    best_permutation = None\n",
    "    worst_permutation = None\n",
    "    #set dummies\n",
    "    g0 = None\n",
    "    h0 = None\n",
    "\n",
    "    #initialize lists\n",
    "    group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "    predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "    counter = 0\n",
    "    \n",
    "    #initialize shapley value dictionary\n",
    "    overall_shapley_values = {}\n",
    "    for item in permutations[0]:\n",
    "        overall_shapley_values[item] = 0\n",
    "        \n",
    "    if max_perms == None:\n",
    "        permutations_set = permutations\n",
    "    else:\n",
    "        permutations_set = []\n",
    "        random_selection = np.random.choice(len(permutations), size=max_perms, replace=False, p=None)\n",
    "        for selection in random_selection:\n",
    "            permutations_set.append(permutations[selection])\n",
    "        \n",
    "    for permutation in permutations_set:\n",
    "        #round count\n",
    "        if counter%10 == 0:\n",
    "            print('Time for ' + str(counter) + ' permutations (seconds):', time.time() - start_time)\n",
    "\n",
    "        #reinitialize model\n",
    "        mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "        mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "        mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "\n",
    "        #position pointer\n",
    "        position = 1\n",
    "\n",
    "        #begin updates\n",
    "        error_without_group_dict = {}\n",
    "\n",
    "        for index in permutation:\n",
    "            improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[index],group_list[index])\n",
    "            if improvement_check:\n",
    "            # run the update & find Shapley contribution\n",
    "                #save model prior to update\n",
    "                file = open('pdl.pkl','wb')\n",
    "                pickle.dump(mod,file)\n",
    "\n",
    "                #make update\n",
    "                cscUpdater.iterative_update(mod, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "\n",
    "                #error if you completed the computation without introducing the group\n",
    "                file = open('pdl.pkl','rb')\n",
    "                mod_without_group = pickle.load(file)\n",
    "                if position != (len(permutation)-1):\n",
    "                    error_without_group = gain_without_group(permutation[position:], mod_without_group, predicate_list, group_list, train_x, train_y, test_x, test_y)\n",
    "                else:\n",
    "                    error_without_group = mod_without_group.test_errors[-1][0]\n",
    "                error_without_group_dict[index] = error_without_group\n",
    "            else:\n",
    "                error_without_group_dict[index] = mod.test_errors[-1][0]\n",
    "            #position pointer update\n",
    "            position += 1\n",
    "\n",
    "        #final permutation error\n",
    "        total_error = mod.test_errors[-1][0]\n",
    "\n",
    "        #add the contributions to the overall shapley array\n",
    "        for key in overall_shapley_values:  \n",
    "            overall_shapley_values[key] = overall_shapley_values[key] + (error_without_group_dict[key] - total_error)\n",
    "\n",
    "        if total_error < best_error:\n",
    "            best_error = total_error\n",
    "            best_permutation = permutation\n",
    "        if total_error > worst_error:\n",
    "            worst_error = total_error\n",
    "            worst_permutation = permutation\n",
    "        counter += 1\n",
    "    average_shapley_values = {}\n",
    "    print(overall_shapley_values)\n",
    "    for key in overall_shapley_values:   \n",
    "        average_shapley_values[key] = overall_shapley_values[key]/len(permutations_set)\n",
    "    finish_time = time.time()\n",
    "    delta_time = finish_time - start_time\n",
    "    print('Best error:',best_error)\n",
    "    print('Best Order:', best_permutation)\n",
    "    print('Worst error:',worst_error)\n",
    "    print('Worst Order:', worst_permutation)\n",
    "    print('Total time (seconds):',delta_time)\n",
    "    print('Average Shapley Values: ', average_shapley_values)\n",
    "    return average_shapley_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b67e4e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 0.0001791666666666747, 5: 0.016854166666666698, 6: 0.0, 10: 0.0001791666666666747}\n"
     ]
    }
   ],
   "source": [
    "print(average_shapley_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a5e85e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 0 permutations (seconds): 5.626678466796875e-05\n",
      "Time for 10 permutations (seconds): 14.524834871292114\n",
      "Time for 20 permutations (seconds): 29.654272317886353\n",
      "Time for 30 permutations (seconds): 41.69549608230591\n",
      "Time for 40 permutations (seconds): 54.43840742111206\n",
      "Time for 50 permutations (seconds): 63.54894781112671\n",
      "Time for 60 permutations (seconds): 78.08669400215149\n",
      "Time for 70 permutations (seconds): 90.05894184112549\n",
      "Time for 80 permutations (seconds): 104.32205200195312\n",
      "Time for 90 permutations (seconds): 116.63544607162476\n",
      "Time for 100 permutations (seconds): 125.48011660575867\n",
      "Time for 110 permutations (seconds): 133.26459336280823\n",
      "{1: 0.0, 5: 2.2346000000000035, 6: 0.15480000000000027, 9: 0.008400000000000407, 10: 0.16320000000000068}\n",
      "Best error: 0.21414999999999995\n",
      "Best Order: (1, 5, 6, 9, 10)\n",
      "Worst error: 0.21414999999999995\n",
      "Worst Order: (1, 5, 6, 9, 10)\n",
      "Total time (seconds): 139.90841674804688\n",
      "Average Shapley Values:  {1: 0.0, 5: 0.018621666666666696, 6: 0.0012900000000000023, 9: 7.00000000000034e-05, 10: 0.0013600000000000057}\n"
     ]
    }
   ],
   "source": [
    "average_shapley_values = find_best_worst_perm(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6ea80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204af83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40368e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d359cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f13199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e984375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "053cf472",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_shapley_values = {\n",
    "1: 0.00016435000000000278, \n",
    "2: 1.6699999999999383e-05, \n",
    "3: -2.099999999999991e-06,\n",
    "4: -1.4999999999999346e-05, \n",
    "5: 0.008999250000000026, \n",
    "6: 0.00010545000000000515, \n",
    "7: 0.0008514500000000084,\n",
    "8: 6.395000000000306e-05, \n",
    "9: -9.14999999999988e-06,\n",
    "10: -8.599999999999608e-06\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8c6fc48f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (647341076.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_12433/647341076.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Best error: 0.21214999999999995\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#100k instances, 10 groups, 1000 random permutations\n",
    "Best error: 0.21214999999999995\n",
    "Best Order: (1, 8, 2, 7, 6, 4, 3, 5, 10, 9)\n",
    "Worst error: 0.21414999999999995\n",
    "Worst Order: (1, 7, 10, 6, 2, 5, 4, 3, 8, 9)\n",
    "Total time (seconds): 2538.2251105308533\n",
    "Average Shapley Values:  {1: 0.00016435000000000278, 2: 1.6699999999999383e-05, 3: -2.099999999999991e-06, 4: -1.4999999999999346e-05, 5: 0.008999250000000026, 6: 0.00010545000000000515, 7: 0.0008514500000000084, 8: 6.395000000000306e-05, 9: -9.14999999999988e-06, 10: -8.599999999999608e-06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "a9dc3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_dictionary_values(d,ascending=True):\n",
    "    sorted_list = []\n",
    "    sorted_tuples = sorted(d.items(), reverse = ascending, key=lambda x: x[1])\n",
    "    for item in sorted_tuples:\n",
    "        sorted_list.append(item[0])\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6283e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_best_perm = sorted_dictionary_values(average_shapley_values,ascending=True)\n",
    "expected_worst_perm = sorted_dictionary_values(average_shapley_values,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f4c30aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected best permutation: [5, 7, 1, 6, 8, 2, 3, 10, 9, 4]\n",
      "Expected worst permutation: [4, 9, 10, 3, 2, 8, 6, 1, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f'Expected best permutation: {expected_best_perm}')\n",
    "print(f'Expected worst permutation: {expected_worst_perm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "644ddf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best expected error: 0.21304999999999996\n"
     ]
    }
   ],
   "source": [
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "for index in expected_best_perm:\n",
    "    cscUpdater.iterative_update(mod, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "print(f'Best expected error: {mod.test_errors[-1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f03e7f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst expected error: 0.21414999999999995\n"
     ]
    }
   ],
   "source": [
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "for index in expected_worst_perm:\n",
    "    cscUpdater.iterative_update(mod, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "print(f'Worst expected error: {mod.test_errors[-1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a6c27f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst expected error: 0.21184999999999998\n"
     ]
    }
   ],
   "source": [
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "for index in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    cscUpdater.iterative_update(mod, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "print(f'Worst expected error: {mod.test_errors[-1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e08cea8",
   "metadata": {},
   "source": [
    "Can we make this work w expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = np.random.choice(len(permutations), size=100, replace=False, p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "287b5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1: 1.2500000000000844e-05, 2: 1.4999999999998349e-06, 3: 1.1999999999998679e-05, 4: 7.999999999999119e-06, 5: 0.01038400000000002, 6: 9.100000000000552e-05, 7: 0.0012170000000000104, 8: 7.4500000000004e-05, 9: 4.999999999999449e-07, 10: -5.149999999999766e-05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1ca61f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 6, 8, 1, 3, 4, 2, 9, 10]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dictionary_values(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c37b7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_dictionary_values(d):\n",
    "    sorted_list = []\n",
    "    sorted_tuples = sorted(d.items(), reverse = True, key=lambda x: x[1])\n",
    "    for item in sorted_tuples:\n",
    "        sorted_list.append(item[0])\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005139a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c19df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
