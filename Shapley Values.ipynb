{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa16bdd8",
   "metadata": {},
   "source": [
    "# Welcome to the Shapley Value Notebook!\n",
    "In this notebook, we begin to examine Shapley Values and algorithms to approximate expected contributions for subgroup-hypothesis pairs in order to find an optimal ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560f282",
   "metadata": {},
   "source": [
    "A few imports that will be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9417b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ducky/.local/lib/python3.8/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sklearn as sk\n",
    "import torch\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import model\n",
    "import verifier\n",
    "import cscUpdater\n",
    "import updater\n",
    "\n",
    "import importlib as imp\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "import dill as pickle\n",
    "\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import acsDataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cef01",
   "metadata": {},
   "source": [
    "Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5dcdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2 #train-test split\n",
    "\n",
    "acs_task = 'income' # options: employment, income, public_coverage, mobility, and travel_time.\n",
    "acs_year = 2018 #must be >= 2014. Upper bound unknown.\n",
    "acs_states = ['CA']\n",
    "acs_horizon='1-Year' #1-Year or 5-Year\n",
    "acs_survey='person' #'person' or 'household'\n",
    "\n",
    "# for subsampling rows: can specify first and last of data to be pulled. currently pulling everything.\n",
    "row_start = 0\n",
    "row_end = 30000\n",
    "\n",
    "# for subsampling columns. note: can only subsample consecutive columns with current implementation\n",
    "col_start=0\n",
    "col_end=-1\n",
    "\n",
    "[train_x, train_y, test_x, test_y, demo_group_functions, demo_group_indicators, min_age, mid_age] = acsDataParallel.get_data(test_size, acs_task, acs_year, acs_states,acs_horizon=acs_horizon, acs_survey=acs_survey, row_start = row_start,row_end = row_end, col_start=col_start, col_end=col_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa5f18",
   "metadata": {},
   "source": [
    "Define 10 subgroup-hypothesis pairs that are accepted when introduced in increasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb5733f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g1(X):\n",
    "    return ((X['WKHP'] == 40))\n",
    "\n",
    "truth_series = g1(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf1 = sk.ensemble.RandomForestClassifier(n_estimators=100, max_depth=11)\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1GPU = convert(clf1, 'pytorch')\n",
    "clf1GPU.to('cuda')\n",
    "\n",
    "def h1(x):\n",
    "    return clf1GPU.predict(x)\n",
    "\n",
    "def g2(X):\n",
    "    return ((X['WKHP'] <= 20))\n",
    "\n",
    "truth_series = g2(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf2 = sk.ensemble.RandomForestClassifier(n_estimators=100, max_depth=11)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf2GPU = convert(clf2, 'pytorch')\n",
    "clf2GPU.to('cuda')\n",
    "def h2(x):\n",
    "    return clf2GPU.predict(x)\n",
    "\n",
    "def g3(X):\n",
    "    return ((X['RAC1P'] >= 3))\n",
    "\n",
    "truth_series = g3(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf3 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=13)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf3GPU = convert(clf3, 'pytorch')\n",
    "clf3GPU.to('cuda')\n",
    "def h3(x):\n",
    "    return clf3GPU.predict(x)\n",
    "\n",
    "def g4(X):\n",
    "    return ((X['RAC1P'] == 1))\n",
    "\n",
    "truth_series = g4(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf4 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=15)\n",
    "clf4.fit(X_train,y_train)\n",
    "clf4GPU = convert(clf4, 'pytorch')\n",
    "clf4GPU.to('cuda')\n",
    "def h4(x):\n",
    "    return clf4GPU.predict(x)\n",
    "\n",
    "def g5(X):\n",
    "    return (X['SCHL'] <= 12)\n",
    "\n",
    "truth_series = g5(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "clf5 = sk.ensemble.RandomForestClassifier(n_estimators=100, max_depth=14)\n",
    "clf5.fit(X_train,y_train)\n",
    "clf5GPU = convert(clf5, 'pytorch')\n",
    "clf5GPU.to('cuda')\n",
    "def h5(x):\n",
    "    return clf5GPU.predict(x)\n",
    "\n",
    "def g6(X):\n",
    "    return (X['SCHL'] >= 16)\n",
    "\n",
    "truth_series = g6(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf6 = sk.ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200,max_depth = 3,random_state=0)\n",
    "clf6.fit(X_train,y_train)\n",
    "clf6GPU = convert(clf6, 'pytorch')\n",
    "clf6GPU.to('cuda')\n",
    "def h6(x):\n",
    "    return clf6GPU.predict(x)\n",
    "\n",
    "def g7(X):\n",
    "    return (X['AGEP'] <=30)\n",
    "\n",
    "truth_series = g7(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "clf7 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100,max_depth = 4,random_state=0)\n",
    "clf7.fit(X_train,y_train)\n",
    "clf7GPU = convert(clf7, 'pytorch')\n",
    "clf7GPU.to('cuda')\n",
    "def h7(x):\n",
    "    return clf7GPU.predict(x)\n",
    "\n",
    "def g8(X):\n",
    "    return (X['COW'] == 1)\n",
    "\n",
    "truth_series = g8(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf8 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=500,max_depth = 3,random_state=0)\n",
    "clf8.fit(X_train,y_train)\n",
    "clf8GPU = convert(clf8, 'pytorch')\n",
    "clf8GPU.to('cuda')\n",
    "\n",
    "def h8(x):\n",
    "    return clf8GPU.predict(x)\n",
    "\n",
    "def g9(X):\n",
    "    return ((X['POBP'] <= 20) & (X['SEX'] == 2))\n",
    "\n",
    "truth_series = g9(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf9 = sk.ensemble.RandomForestClassifier(n_estimators=200, max_depth=15)\n",
    "clf9.fit(X_train,y_train)\n",
    "clf9GPU = convert(clf9, 'pytorch')\n",
    "clf9GPU.to('cuda')\n",
    "def h9(x):\n",
    "    return clf9GPU.predict(x)\n",
    "\n",
    "def g10(X):\n",
    "    return ((X['OCCP'] <= 100))\n",
    "\n",
    "truth_series = g10(train_x)\n",
    "X_train = train_x[truth_series]\n",
    "y_train = train_y[truth_series]\n",
    "\n",
    "clf10 = ensemble.GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=30,max_depth = 4,random_state=0)\n",
    "clf10.fit(X_train,y_train)\n",
    "clf10GPU = convert(clf10, 'pytorch')\n",
    "clf10GPU.to('cuda')\n",
    "def h10(x):\n",
    "    return clf10GPU.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e6ada22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_size(x, group):\n",
    "# helper function that checks that the discovered group isn't too small to run on\n",
    "    g_indices = group(x) == 1\n",
    "    g_xs = x[g_indices]\n",
    "    if len(g_xs) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45b843d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = DecisionTreeClassifier(max_depth = 1, random_state=0)\n",
    "initial_model.fit(train_x, train_y);\n",
    "\n",
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "868024e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_shapley_value(mod,permutation, group_list, predicate_list):\n",
    "    \n",
    "    contribution_array = np.zeros(len(permutation))\n",
    "    \n",
    "    file = open('pdl.pkl','wb')\n",
    "    pickle.dump(mod,file)\n",
    "    \n",
    "    for value in permutation:\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[value],group_list[value])\n",
    "        if improvement_check:\n",
    "            # run the update\n",
    "            cscUpdater.iterative_update(mod, predicate_list[value], group_list[value], train_x, train_y, test_x, test_y, 'g'+str(value))\n",
    "            \n",
    "    permutation_error = sk.metrics.zero_one_loss(test_y,np.array(mod.predict(test_x),dtype=bool))\n",
    "    \n",
    "\n",
    "    for value in permutation:\n",
    "        #load file\n",
    "        file = open('pdl.pkl','rb')\n",
    "        mod = pickle.load(file)\n",
    "        #final error of permuation\n",
    "        for sub_value in permutation[permutation.index(value)+1:]:\n",
    "            improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[sub_value],group_list[sub_value])\n",
    "            if improvement_check:\n",
    "            # run the update\n",
    "                cscUpdater.iterative_update(mod, predicate_list[sub_value], group_list[sub_value], train_x, train_y, test_x, test_y, 'g'+str(sub_value))\n",
    "        error_without_group = sk.metrics.zero_one_loss(test_y,np.array(mod.predict(test_x),dtype=bool))\n",
    "        \n",
    "        contribution_array[value] += (error_without_group - permutation_error)\n",
    "        \n",
    "        #reload file\n",
    "        file = open('pdl.pkl','rb')\n",
    "        mod = pickle.load(file)\n",
    "        \n",
    "        improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[value],group_list[value])\n",
    "        if improvement_check:\n",
    "            # run the update\n",
    "            cscUpdater.iterative_update(mod, predicate_list[value], group_list[value], train_x, train_y, test_x, test_y, 'g'+str(value))\n",
    "        \n",
    "        file = open('pdl.pkl','wb')\n",
    "        pickle.dump(mod,file)\n",
    "    return contribution_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "23119ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "predicate_list = [h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e63a4b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_model = DecisionTreeClassifier(max_depth = 1, random_state=0)\n",
    "initial_model.fit(train_x, train_y);\n",
    "\n",
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "contribution = fractional_shapley_value(mod,[0,1,2,3,4,5,7,6], group_list, predicate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "e1ef9cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00016667,  0.002     ,  0.00033333,  0.00016667,  0.0005    ,\n",
       "        0.00266667,  0.        ,  0.00116667])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "afe13abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error incluiding g1: 0.15533333333333332\n",
      " Error not incluiding g1: 0.15516666666666667\n"
     ]
    }
   ],
   "source": [
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "\n",
    "for value in [0,1,2,3,4,5,7,6]:\n",
    "    improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[value],group_list[value])\n",
    "    if improvement_check:\n",
    "        # run the update\n",
    "        cscUpdater.iterative_update(mod, predicate_list[value], group_list[value], train_x, train_y, test_x, test_y, 'g'+str(value))\n",
    "print(f' Error incluiding g1: {mod.test_errors[-1][0]}')\n",
    "\n",
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "\n",
    "for value in [1,2,3,4,5,7,6]:\n",
    "    improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[value],group_list[value])\n",
    "    if improvement_check:\n",
    "        # run the update\n",
    "        cscUpdater.iterative_update(mod, predicate_list[value], group_list[value], train_x, train_y, test_x, test_y, 'g'+str(value))\n",
    "print(f' Error not incluiding g1: {mod.test_errors[-1][0]}')     \n",
    "print('Incluiding g1 in this permutation hurts the overall accuracy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39841f4",
   "metadata": {},
   "source": [
    "Now, we define a permutation with the Shapley Values in increasing order, but we force negative values to be at the end of the permutation since we know them to hurt more than they help. We want to add those groups which may only contribute a small amount on average first so they are not forgotten in later rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fb3fd88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapley_ordering(contribution):\n",
    "#     for index in range(len(contribution)):\n",
    "#         if contribution[index] < 0:\n",
    "#             contribution[index] = 1\n",
    "    return np.flip(np.argsort(contribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7bd41199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_pdl_error(ordering):\n",
    "    mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "    mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "    mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "    for value in ordering:\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(mod, test_x, test_y, predicate_list[value],group_list[value])\n",
    "        if improvement_check:\n",
    "            # run the update\n",
    "            cscUpdater.iterative_update(mod, predicate_list[value], group_list[value], train_x, train_y, test_x, test_y, 'g'+str(value))\n",
    "    print(f' Shapley Ordering Error: {mod.test_errors[-1][0]}')      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4561aa4",
   "metadata": {},
   "source": [
    "We now attempt to take the average Shapley Value over many permutations to see of there is correlation with this metric. Using 8 groups, we will take permutations and output the ordering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      " Shapley Ordering Error: 0.15549999999999997\n",
      "361\n",
      "362\n",
      "363\n"
     ]
    }
   ],
   "source": [
    "#define groups used for permutations\n",
    "groups=[0,1,2,3,4,5,6,7]\n",
    "\n",
    "#running shapley value contribution totals\n",
    "shapley_array = np.zeros(len(groups))\n",
    "\n",
    "#all possible permutations\n",
    "permutations_list = list(itertools.permutations(groups))\n",
    "\n",
    "#define which permutations we will take\n",
    "selection = np.random.choice(len(permutations_list), size=10000, replace=False, p=None)\n",
    "\n",
    "mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "mod.test_errors.append(cscUpdater.measure_group_errors(mod, test_x, test_y))\n",
    "mod.train_errors.append(cscUpdater.measure_group_errors(mod, train_x, train_y))\n",
    "\n",
    "#save base PDL\n",
    "file = open('basepdl.pkl','wb')\n",
    "pickle.dump(mod,file)\n",
    "   \n",
    "#intialize df to record shapley values\n",
    "shapley_df = pd.DataFrame(columns= groups)\n",
    "\n",
    "#initialize counter\n",
    "counter = 1\n",
    "\n",
    "for index in selection:\n",
    "    \n",
    "    #reload base PDL  \n",
    "    file = open('basepdl.pkl','rb')\n",
    "    mod = pickle.load(file)\n",
    "    \n",
    "    #define ordering\n",
    "    permutation = permutations_list[index]\n",
    "    \n",
    "    #get fractional contributions\n",
    "    fractional_contribution = fractional_shapley_value(mod,permutation, group_list, predicate_list)\n",
    "\n",
    "    #add fractional contribution\n",
    "    shapley_array += fractional_contribution\n",
    "    \n",
    "    if counter%10 == 0:\n",
    "        #prints the error of the PDL using Shapley Values to determine ordering\n",
    "        output_pdl_error(get_shapley_ordering(shapley_array))\n",
    "        \n",
    "    shapley_df.loc[counter] = fractional_contribution\n",
    "    counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1d44b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shapley Ordering Error: 0.15533333333333332\n"
     ]
    }
   ],
   "source": [
    "output_pdl_error(get_shapley_ordering(shapley_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "89eb01b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002667</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.003667</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.002833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.003500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.001667</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "1   0.002500  0.000000  0.000000  0.000000  0.001833  0.003000  0.000833   \n",
       "2   0.000667  0.000000 -0.000833  0.000000  0.000667  0.001833  0.000000   \n",
       "3   0.000000  0.000000  0.000000 -0.002667  0.000500  0.000500  0.000000   \n",
       "4   0.000000  0.000000 -0.000333 -0.001667  0.000167  0.001833  0.000333   \n",
       "5   0.000000  0.000000  0.000000  0.000000  0.000667  0.002333  0.001000   \n",
       "6   0.000667  0.000333  0.000000  0.000000  0.000667  0.003333  0.000833   \n",
       "7   0.000000  0.000000  0.000000  0.000500  0.000500  0.003500  0.002500   \n",
       "8  -0.001333 -0.001167 -0.001167 -0.003667  0.000333  0.000000  0.000167   \n",
       "9   0.000000  0.000000  0.000167 -0.001000  0.000167  0.002000  0.000333   \n",
       "10  0.000000  0.000000  0.000000  0.000000  0.000667  0.002167  0.001000   \n",
       "11 -0.000167  0.000500  0.000000  0.000000  0.000500  0.006000  0.003500   \n",
       "12  0.000000  0.000000  0.000000  0.000000  0.000667  0.003167  0.001000   \n",
       "13  0.000000  0.000167  0.000000  0.000000  0.000000  0.003000  0.002167   \n",
       "14  0.000833  0.000333  0.000000  0.000000  0.000667  0.003500  0.001333   \n",
       "15 -0.000167  0.000167  0.000000 -0.000333  0.000500  0.003333  0.000667   \n",
       "16 -0.001667 -0.000833 -0.001500 -0.003500  0.000500  0.000000  0.000000   \n",
       "17 -0.000167  0.000333  0.000000 -0.000500  0.000167  0.006167  0.002000   \n",
       "18 -0.001667 -0.000833 -0.001500 -0.004000  0.000500  0.000000  0.000000   \n",
       "19  0.000000  0.000000  0.000000 -0.001500  0.000167  0.001167  0.000667   \n",
       "20  0.000333  0.000667  0.000000 -0.002333  0.000167  0.004167  0.000167   \n",
       "\n",
       "           7  \n",
       "1   0.001833  \n",
       "2   0.001000  \n",
       "3   0.000333  \n",
       "4   0.000000  \n",
       "5   0.002167  \n",
       "6   0.001500  \n",
       "7   0.002000  \n",
       "8  -0.000833  \n",
       "9   0.000000  \n",
       "10  0.002167  \n",
       "11  0.002833  \n",
       "12  0.002167  \n",
       "13  0.002167  \n",
       "14  0.002500  \n",
       "15  0.002167  \n",
       "16 -0.001500  \n",
       "17  0.002333  \n",
       "18 -0.001000  \n",
       "19  0.000500  \n",
       "20  0.000667  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e628d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = np.random.choice(len(permutations), size=100, replace=False, p=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005139a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "518ee537",
   "metadata": {},
   "source": [
    "# Greedy Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48d129",
   "metadata": {},
   "source": [
    "Instead of randomly choosing permutations and computing Shapley Values for arbitrary places, could we greedily build our Pointer Decision List by the best current update? I.e., if given G, compute an expected Shapley Value given that the update has to be the first update. Compute over all groups and then choose the best from that way. Makes sense that if a group makes a big impact, you probably want to pick it then vice later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b436902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pdl(initial_mod, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y):\n",
    "    for index in permutation:\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(initial_mod, test_x, test_y, predicate_list[index], group_list[index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(initial_mod, predicate_list[index], group_list[index], train_x, train_y, test_x, test_y, 'g'+str(index))\n",
    "    return initial_mod.test_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4f13e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 3, 4, 5, 6, 7]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21130000000000004\n",
      "0.21130000000000004\n",
      "0.21130000000000004\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "2\n",
      "[1, 3, 4, 5, 6, 7]\n",
      "0.21245000000000003\n",
      "0.21109999999999995\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21075\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.2108\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21109999999999995\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.2118\n",
      "0.21245000000000003\n",
      "3\n",
      "[1, 2, 4, 5, 6, 7]\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.2116\n",
      "0.21145000000000003\n",
      "0.2116\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.21155000000000002\n",
      "0.21175\n",
      "0.21155000000000002\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "0.2116\n",
      "0.21145000000000003\n",
      "0.2116\n",
      "0.2126\n",
      "0.21245000000000003\n",
      "0.2126\n",
      "4\n",
      "[1, 2, 3, 5, 6, 7]\n",
      "0.21109999999999995\n",
      "0.21204999999999996\n",
      "0.21109999999999995\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.2116\n",
      "0.21245000000000003\n",
      "0.2116\n",
      "0.2118\n",
      "0.21145000000000003\n",
      "0.2118\n",
      "0.2118\n",
      "0.21245000000000003\n",
      "0.2118\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "5\n",
      "[1, 2, 3, 4, 6, 7]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21130000000000004\n",
      "0.21130000000000004\n",
      "0.21130000000000004\n",
      "6\n",
      "[1, 2, 3, 4, 5, 7]\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21255000000000002\n",
      "0.21245000000000003\n",
      "0.21255000000000002\n",
      "0.21289999999999998\n",
      "0.21245000000000003\n",
      "0.21289999999999998\n",
      "0.21165\n",
      "0.21245000000000003\n",
      "0.21165\n",
      "0.21184999999999998\n",
      "0.21245000000000003\n",
      "0.21184999999999998\n",
      "0.21289999999999998\n",
      "0.21245000000000003\n",
      "0.21289999999999998\n",
      "0.21255000000000002\n",
      "0.21245000000000003\n",
      "0.21255000000000002\n",
      "0.21125000000000005\n",
      "0.21245000000000003\n",
      "0.21125000000000005\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21289999999999998\n",
      "0.21245000000000003\n",
      "0.21289999999999998\n",
      "7\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21235000000000004\n",
      "0.21245000000000003\n",
      "0.21235000000000004\n",
      "0.21245000000000003\n",
      "0.21175\n",
      "0.21245000000000003\n",
      "0.21184999999999998\n",
      "0.21245000000000003\n",
      "0.21184999999999998\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21145000000000003\n",
      "0.21165\n",
      "0.21145000000000003\n",
      "0.21245000000000003\n",
      "0.21130000000000004\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.2116\n",
      "0.21245000000000003\n",
      "0.21235000000000004\n",
      "0.21245000000000003\n",
      "0.21235000000000004\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g1,g2,g3,g4,g5,g6,g7]\n",
    "predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8fc54384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  6.70000000e-03,  1.15000000e-03, -3.33066907e-16,\n",
       "        0.00000000e+00, -5.00000000e-05,  1.70000000e-03])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d44a4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 3, 4, 5, 6]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "2\n",
      "[1, 3, 4, 5, 6]\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "0.21275\n",
      "0.21245000000000003\n",
      "0.21275\n",
      "3\n",
      "[1, 2, 4, 5, 6]\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "0.21284999999999998\n",
      "0.21245000000000003\n",
      "0.21284999999999998\n",
      "4\n",
      "[1, 2, 3, 5, 6]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "5\n",
      "[1, 2, 3, 4, 6]\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21245000000000003\n",
      "0.21294999999999997\n",
      "6\n",
      "[1, 2, 3, 4, 5]\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "0.21245000000000003\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g1,g3,g4,g5,g6,g7]\n",
    "predicate_list = [h0,h1,h3,h4,h5,h6,h7]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66bbf7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.003, 0.004, 0.   , 0.005, 0.   ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff3f28be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 3, 4, 5]\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "0.21484999999999999\n",
      "0.21294999999999997\n",
      "0.21484999999999999\n",
      "2\n",
      "[1, 3, 4, 5]\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "0.21630000000000005\n",
      "0.21294999999999997\n",
      "0.21630000000000005\n",
      "3\n",
      "[1, 2, 4, 5]\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.21294999999999997\n",
      "0.22829999999999995\n",
      "4\n",
      "[1, 2, 3, 5]\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "0.21294999999999997\n",
      "5\n",
      "[1, 2, 3, 4]\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "0.2138\n",
      "0.21294999999999997\n",
      "0.2138\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g1,g3,g4,g5,g7]\n",
    "predicate_list = [h0,h1,h3,h4,h5,h7]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g6')\n",
    "\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d80112a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.019 , 0.0335, 0.1535, 0.    , 0.0085])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bebd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 3, 4]\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "0.248\n",
      "0.22829999999999995\n",
      "0.248\n",
      "2\n",
      "[1, 3, 4]\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "0.23165000000000002\n",
      "0.22829999999999995\n",
      "0.23165000000000002\n",
      "3\n",
      "[1, 2, 4]\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "0.22829999999999995\n",
      "4\n",
      "[1, 2, 3]\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0.23860000000000003\n",
      "0.22829999999999995\n",
      "0.23860000000000003\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g1,g3,g5,g7]\n",
    "predicate_list = [h0,h1,h3,h5,h7]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g6')\n",
    "cscUpdater.iterative_update(current_model, h4, g4, train_x, train_y, test_x, test_y, 'g4')\n",
    "\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc256b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1182, 0.0201, 0.    , 0.0618])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapley_by_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d2a5ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2, 3]\n",
      "0.25675000000000003\n",
      "0.248\n",
      "0.25675000000000003\n",
      "0.25675000000000003\n",
      "0.248\n",
      "0.25675000000000003\n",
      "2\n",
      "[1, 3]\n",
      "0.248\n",
      "0.248\n",
      "0.248\n",
      "0.248\n",
      "0.248\n",
      "0.248\n",
      "3\n",
      "[1, 2]\n",
      "0.26249999999999996\n",
      "0.248\n",
      "0.26249999999999996\n",
      "0.26249999999999996\n",
      "0.248\n",
      "0.26249999999999996\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g3,g5,g7]\n",
    "predicate_list = [h0,h3,h5,h7]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g6')\n",
    "cscUpdater.iterative_update(current_model, h4, g4, train_x, train_y, test_x, test_y, 'g4')\n",
    "cscUpdater.iterative_update(current_model, h1, g1, train_x, train_y, test_x, test_y, 'g4')\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e491f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[2]\n",
      "0.28085000000000004\n",
      "0.26249999999999996\n",
      "0.28085000000000004\n",
      "2\n",
      "[1]\n",
      "0.26249999999999996\n",
      "0.26249999999999996\n",
      "0.26249999999999996\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#number of permutations to use to estimate Shapley Values\n",
    "estimation_instances = 10\n",
    "\n",
    "\n",
    "#dummies\n",
    "g0 = None\n",
    "h0 = None\n",
    "\n",
    "#define initial group list\n",
    "# group_list = [g0,g1,g2,g3,g4,g5,g6,g7,g8,g9,g10]\n",
    "# predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7,h8,h9,h10]\n",
    "\n",
    "group_list = [g0,g3,g5]\n",
    "predicate_list = [h0,h3,h5]\n",
    "\n",
    "#initialize model\n",
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g6')\n",
    "cscUpdater.iterative_update(current_model, h4, g4, train_x, train_y, test_x, test_y, 'g4')\n",
    "cscUpdater.iterative_update(current_model, h1, g1, train_x, train_y, test_x, test_y, 'g1')\n",
    "cscUpdater.iterative_update(current_model, h7, g7, train_x, train_y, test_x, test_y, 'g7')\n",
    "\n",
    "#store\n",
    "file = open('pdl.pkl','wb')\n",
    "pickle.dump(current_mod,file)\n",
    "\n",
    "#use intermediaries\n",
    "remaining_group_indices = list(range(1,len(group_list)))\n",
    "\n",
    "#define current shapley contributions relative to position\n",
    "shapley_by_position = np.zeros(len(remaining_group_indices))\n",
    "\n",
    "#working group list\n",
    "position = 0\n",
    "for group_index in remaining_group_indices:\n",
    "    print(group_index)\n",
    "    working_copy = copy.copy(remaining_group_indices)\n",
    "    \n",
    "    working_copy.pop(position)\n",
    "    \n",
    "    print(working_copy)\n",
    "    \n",
    "    possible_orderings = list(itertools.permutations(working_copy))\n",
    "    \n",
    "    if estimation_instances > len(possible_orderings):\n",
    "        estimation_counter = len(possible_orderings)\n",
    "    else:\n",
    "        estimation_counter = estimation_instances\n",
    "    \n",
    "    subset_indices = np.random.choice(len(possible_orderings), size=estimation_counter, replace=False, p=None) \n",
    "    random_permutations = []\n",
    "    for selection in subset_indices:\n",
    "        random_permutations.append(possible_orderings[selection])\n",
    "    for permutation in random_permutations:\n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        error_without_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_without_group)\n",
    "        \n",
    "        file = open('pdl.pkl','rb')\n",
    "        current_model = pickle.load(file)\n",
    "        improvement_check = verifier.is_proposed_group_good_csc(current_model, test_x, test_y, predicate_list[group_index], group_list[group_index])\n",
    "        if improvement_check:\n",
    "            cscUpdater.iterative_update(current_model, predicate_list[group_index], group_list[group_index], train_x, train_y, test_x, test_y, 'g'+str(group_index))\n",
    "        error_with_group = build_pdl(current_model, group_list, predicate_list, permutation, train_x, train_y, test_x, test_y)\n",
    "        print(error_with_group)\n",
    "        print(error_without_group)\n",
    "        shapley_contribution = error_without_group - error_with_group\n",
    "        \n",
    "        shapley_by_position[group_index-1] += shapley_contribution\n",
    "    position += 1                                     \n",
    "best = np.argmax(shapley_by_position)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fddaf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21245000000000003"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g6')\n",
    "cscUpdater.iterative_update(current_model, h4, g4, train_x, train_y, test_x, test_y, 'g4')\n",
    "cscUpdater.iterative_update(current_model, h1, g1, train_x, train_y, test_x, test_y, 'g1')\n",
    "cscUpdater.iterative_update(current_model, h7, g7, train_x, train_y, test_x, test_y, 'g7')\n",
    "cscUpdater.iterative_update(current_model, h3, g3, train_x, train_y, test_x, test_y, 'g3')\n",
    "cscUpdater.iterative_update(current_model, h5, g5, train_x, train_y, test_x, test_y, 'g5')\n",
    "current_model.test_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "35906a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21145000000000003"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "cscUpdater.iterative_update(current_model, h1, g1, train_x, train_y, test_x, test_y, 'g2')\n",
    "cscUpdater.iterative_update(current_model, h2, g2, train_x, train_y, test_x, test_y, 'g6')\n",
    "cscUpdater.iterative_update(current_model, h3, g3, train_x, train_y, test_x, test_y, 'g4')\n",
    "cscUpdater.iterative_update(current_model, h4, g4, train_x, train_y, test_x, test_y, 'g1')\n",
    "cscUpdater.iterative_update(current_model, h5, g5, train_x, train_y, test_x, test_y, 'g7')\n",
    "cscUpdater.iterative_update(current_model, h6, g6, train_x, train_y, test_x, test_y, 'g3')\n",
    "cscUpdater.iterative_update(current_model, h7, g7, train_x, train_y, test_x, test_y, 'g5')\n",
    "current_model.test_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "56d509ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21145000000000003"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_mod = model.PointerDecisionList(initial_model.predict, [])\n",
    "current_mod.test_errors.append(cscUpdater.measure_group_errors(current_mod, test_x, test_y))\n",
    "current_mod.train_errors.append(cscUpdater.measure_group_errors(current_mod, train_x, train_y))\n",
    "group_list = [g0,g1,g2,g3,g4,g5,g6,g7]\n",
    "predicate_list = [h0,h1,h2,h3,h4,h5,h6,h7]\n",
    "for i in [6,4,1,5,3,7,2]:\n",
    "    cscUpdater.iterative_update(current_model, predicate_list[i], group_list[i], train_x, train_y, test_x, test_y, 'g5')\n",
    "current_model.test_errors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15fc04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
